<!DOCTYPE html>

<html lang="en" data-content_root="../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Introduction to Big Data Analytics</title>
    <link rel="stylesheet" type="text/css" href="../_static/revealjs/dist/reveal.css?v=40f0a724" />
    <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/revealjs/plugin/highlight/zenburn.css?v=83d5745d" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

  </head><body>
    <div class="reveal">
        <div class="slides" role="main">
            <section >
<section data-background-color="white" data-background-image="../_static/logo.png" data-background-size="50%" data-background-position="top center" data-background-repeat="no-repeat">
<h1>Introduction to Big Data Analytics</h1>
<div class="subtitle docutils container">
<p><strong>Development Environment for Spark</strong></p>
<p>Xingang (Ian) Fang</p>
</div>
</section>
</section>
<section >
<section >
<h2>TL;DR</h2>
<ul class="simple">
<li><p>We cover Spark using Scala but I will accept assignments written in Python</p></li>
<li><p>The recommended Databricks Community Edition has everything we need for the
course: Notebook interface + Web terminal</p></li>
<li><p>Use docker container with Spark if you prefer command line interface on your
local machine (Optional)</p></li>
</ul>
</section>
</section>
<section >
<section >
<h2>Outline</h2>
<ul class="simple">
<li><p>Simplified Development Environment in Teaching</p></li>
<li><p>Two ways of data processing with Spark</p></li>
<li><p>Programming language for Spark</p></li>
<li><p>Two recommended development environments</p></li>
</ul>
</section>
</section>
<section >
<section >
<h2>Simplified Development Environment in Teaching</h2>
<ul class="simple">
<li><p>In production</p>
<ul>
<li><p>on cluster</p></li>
<li><p>command line interface through SSH</p></li>
</ul>
</li>
<li><p>In teaching</p>
<ul>
<li><p>single node, local or remote</p></li>
<li><p>Notebook interface or command line interface</p></li>
</ul>
</li>
</ul>
</section>
</section>
<section >
<section >
<h2>Data Processing with Spark</h2>
<ul class="simple">
<li><p>Interactive data processing</p>
<ul>
<li><p>Run code interactively to allow frequent result checking</p></li>
<li><p>Interfaces</p>
<ul>
<li><p>Spark REPL (read-evaluate-print loop) shell</p></li>
<li><p>Jupyter notebook like interface</p></li>
</ul>
</li>
<li><p>Application: data exploration, data cleaning, data transformation</p></li>
</ul>
</li>
<li><p>Batch data processing</p>
<ul>
<li><p>Run finished code all at once</p></li>
<li><p>Interfaces</p>
<ul>
<li><p>Spark submit, submit finished application to Spark cluster</p></li>
</ul>
</li>
<li><p>Application: end-to-end data processing</p></li>
</ul>
</li>
</ul>
</section>
</section>
<section >
<section >
<h2>Programming Language for Spark</h2>
<ul class="simple">
<li><p>Spark supports Scala, Java, Python, SQL and R</p></li>
<li><p>Scala</p>
<ul>
<li><p>the native language for Spark</p></li>
<li><p>not a popular language elsewhere</p></li>
<li><p>harder to setup and use but not too bad using Docker</p></li>
<li><p>our textbook uses Scala</p></li>
</ul>
</li>
<li><p>Python</p>
<ul>
<li><p>some students may already know Python</p></li>
<li><p>the most popular language for data processing</p></li>
<li><p>easier to install and use (may use Google Colab)</p></li>
</ul>
</li>
<li><p>SQL (Spark SQL)</p>
<ul>
<li><p>Spark SQL is a subset of SQL</p></li>
<li><p>Spark SQL is the most popular interface for Spark</p></li>
</ul>
</li>
<li><p>The course is taught in Scala but I will take assignments written in Python</p></li>
</ul>
</section>
</section>
<section >
<section >
<h2>Recommended Development Environments</h2>
<ul class="simple">
<li><p>Notebook interface for interactive data processing</p>
<ul>
<li><p>Databricks Community Edition</p></li>
</ul>
</li>
<li><p>Command line interface for both interactive and batch data processing</p>
<ul>
<li><p>Web terminal in Databricks Community Edition</p></li>
<li><p>Docker container with Spark</p></li>
</ul>
</li>
<li><p>If you want to install Spark on your own machine, please refer to the
official documentation and free online tutorials</p></li>
</ul>
</section>
<section >
<h3>Databricks Community Edition</h3>
<ul class="simple">
<li><p>Databricks is a company founded by the creators of Spark</p></li>
<li><p>Databricks Community Edition is a free version of Databricks service</p></li>
<li><p>Learn how to register <a class="reference external" href="https://docs.databricks.com/en/getting-started/community-edition.html">here</a></p></li>
<li><p>This service provides you a virtual cluster with a notebook interface and
other web interfaces to manage your cluster write code in Spark</p></li>
<li><p>You can also use a web terminal to run shell commands</p></li>
<li><p>Access the service <a class="reference external" href="https://community.cloud.databricks.com/">here</a></p></li>
</ul>
</section>
<section >
<h3>DataBricks Community Edition cont.</h3>
<ul class="simple">
<li><p>Pro</p>
<ul>
<li><p>Notebook interface is easy to use</p></li>
<li><p>Web terminal interface is available if you prefer command line interface</p></li>
<li><p>No need to install software</p></li>
<li><p>The professional version is widely used in the industry</p></li>
</ul>
</li>
<li><p>Con</p>
<ul>
<li><p>Slow to start the compute/cluster (but you only need to start it once)</p></li>
<li><p>Data download is cumbersome</p></li>
</ul>
</li>
<li><p>Conclusion: Good enough for this course</p></li>
<li><p>More instructions <a class="reference internal" href="dce.html"><span class="doc">here</span></a></p></li>
</ul>
</section>
<section >
<h3>Docker Container with Spark</h3>
<ul class="simple">
<li><p>Installation of Spark is not trivial</p>
<ul>
<li><p>install JDK, Scala, Spark, Hadoop, and configure each of them</p></li>
</ul>
</li>
<li><p>Run pre-built Docker image with Spark will be consistent and easier</p>
<ul>
<li><p>A single docker pull</p></li>
</ul>
</li>
<li><p>Docker is a platform for developing, shipping, and running applications
inside containers</p></li>
<li><p>Docker desktop software is available for Windows and Mac OS</p>
<ul>
<li><p>Guess what? Linux has native support for Docker without Docker desktop</p></li>
</ul>
</li>
<li><p>More instructions <a class="reference internal" href="docker.html"><span class="doc">here</span></a></p></li>
</ul>
</section>
</section>

        </div>
    </div>
    
    <script src="../_static/revealjs/dist/reveal.js"></script>
    
    
      <script src="../_static/revealjs/plugin/notes/notes.js"></script>
      <script src="../_static/revealjs/plugin/highlight/highlight.js"></script>
      <script src="../_static/revealjs/plugin/math/math.js"></script>
      
    
    <script>
        var revealjsConfig = new Object();
        Object.assign(revealjsConfig, {"controls": true, "progress": true, "hash": true, "center": true, "transition": "slide", "slideNumber": true, "scrollActivationWidth": null});
        
        
        
          revealjsConfig.plugins = [
            RevealNotes,RevealHighlight,RevealMath,
          ];
        
        // More info https://github.com/hakimel/reveal.js#configuration
        Reveal.initialize(revealjsConfig);
    </script>

  </body>
</html>